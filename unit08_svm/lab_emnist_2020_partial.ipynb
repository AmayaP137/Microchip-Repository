{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzEgIoIBnetd"
      },
      "source": [
        "# Lab: SVMs on Extended MNIST\n",
        "\n",
        "In the [MNIST demo](demo_mnist_svm.ipynb), we saw how SVMs can be used for the classic MNIST problem of digit recognition. In this lab, we are going to extend the MNIST dataset by adding a number of non-digit letters and see if the classifier can distinguish the digits from the non-digits. All non-digits will be lumped as a single 11-th class. This is a highly simplified version of 'detection' problem (as opposed to 'classification' problem). Detection is vital in OCR and related problems since the non useful characters must be rejected.\n",
        "\n",
        "In addition to the concepts in the demo, you will learn:\n",
        "* Combine multiple datasets\n",
        "* Select the SVM parameters (`C` and `gamma`) via cross-validation.\n",
        "* Use the `GridSearchCV` method to search for parameters with cross-validation.\n",
        "\n",
        "Note:  An [earlier version](lab_emnist_2017_partial.ipynb) of this lab made you manually create the combined letter and digit data.  In this lab, we will download the data from NIST website.  But, the old lab is still useful to look at if you want to see how to use `skimage` package for a number of image pre-processing tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFsaO79Bnete"
      },
      "source": [
        "As usual, we download the standard packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "id": "FKJPAy_Cnete"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn import linear_model, preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eqwQU0Dnetf"
      },
      "source": [
        "## Downloading the EMNIST Dataset\n",
        "\n",
        "After creating the highly popular MNIST dataset, NIST created an extended version of the dataset to include letters and digits.     The extended datase (called EMNIST) also has many more examples per class.  \n",
        "\n",
        "To download the data, first go to the [EMNIST webpage](https://www.nist.gov/itl/iad/image-group/emnist-dataset).  Near the bottom, you will see a link for `MATLAB format dataset`.  If you click on this link, you will download a `zip` file with several datasets in it.  The total file is 726M, so it may take some time and diskspace to download.  Extract two files:\n",
        "* `emnist-digits.mat`:  This is a file of digits `0` to `9`, but with more examples per class.\n",
        "* `emnist-letters.mat`:  This is a file of letters `a/A` to `z/Z`.  The lower and upper case letters are grouped into the same class.\n",
        "\n",
        "Once you get these two files, you can save yourself the diskspace and remove all the other files.\n",
        "\n",
        "You can download the files manually, or you can run the following commands which will download the files automatically.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWs4LPGZzUCU",
        "outputId": "5ddb565a-9538-4345-8d17-0c1906892f46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrmgDWy4netf",
        "outputId": "3f106ec9-491c-45af-d806-c39e74f4a77d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted EMNIST files already exist. Skipping download and unzip.\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import requests\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def download_file(src_url, dst_fn):\n",
        "\n",
        "    if os.path.exists(dst_fn):\n",
        "        print('File %s already exists' % dst_fn)\n",
        "        return\n",
        "\n",
        "    print('Downloading %s' % dst_fn)\n",
        "\n",
        "    # Streaming, so we can iterate over the response.\n",
        "    r = requests.get(src_url, stream=True)\n",
        "\n",
        "    # Total size in MB.\n",
        "    total_size = int(r.headers.get('content-length', 0));\n",
        "    block_size = 1024\n",
        "    wrote = 0\n",
        "    with open(dst_fn, 'wb') as f:\n",
        "        with tqdm(total=total_size//block_size, unit='kB',\n",
        "                           unit_scale=True, unit_divisor=1024) as pbar:\n",
        "            for data in r.iter_content(block_size):\n",
        "                wrote = wrote + len(data)\n",
        "                pbar.update(1)\n",
        "                f.write(data)\n",
        "    if total_size != 0 and wrote != total_size:\n",
        "        print(\"ERROR, something went wrong\")\n",
        "\n",
        "# Get file names and paths\n",
        "matlab_dir = '/content/drive/MyDrive/matlab/matlab'\n",
        "digits_fn =  os.path.join(matlab_dir,'emnist-digits.mat')\n",
        "letters_fn = os.path.join(matlab_dir,'emnist-letters.mat')\n",
        "dst_fn = 'matlab.zip'\n",
        "src_url = \"https://nist.gov/itl/products-and-services/emnist-dataset\"\n",
        "\n",
        "# Check if extracted EMNIST files already exist\n",
        "if os.path.exists(matlab_dir) and os.path.exists(digits_fn) and os.path.exists(letters_fn):\n",
        "    print('Extracted EMNIST files already exist. Skipping download and unzip.')\n",
        "else:\n",
        "    # Extracted files do not exist, proceed to check/download/unzip the zip file\n",
        "    needs_download = False\n",
        "    if not os.path.exists(dst_fn):\n",
        "        print(f'Zip file {dst_fn} not found. Will attempt download.')\n",
        "        needs_download = True\n",
        "    else:\n",
        "        print(f'Zip file {dst_fn} found. Attempting to unzip...')\n",
        "        try:\n",
        "            with zipfile.ZipFile(dst_fn, 'r') as zip_ref:\n",
        "                # Test the zip file's integrity before extracting\n",
        "                if zip_ref.testzip() is not None:\n",
        "                    print(f'Warning: {dst_fn} is corrupted. Deleting and re-downloading.')\n",
        "                    os.remove(dst_fn)\n",
        "                    needs_download = True\n",
        "                else:\n",
        "                    print(f'Unzipping {dst_fn}...')\n",
        "                    zip_ref.extractall('.')\n",
        "                    print('Unzip completed.')\n",
        "        except zipfile.BadZipFile:\n",
        "            print(f'Error: {dst_fn} is not a valid zip file. Deleting and re-downloading.')\n",
        "            os.remove(dst_fn)\n",
        "            needs_download = True\n",
        "        except Exception as e:\n",
        "            print(f'An unexpected error occurred during unzipping: {e}. Deleting and re-downloading.')\n",
        "            if os.path.exists(dst_fn):\n",
        "                os.remove(dst_fn)\n",
        "            needs_download = True\n",
        "\n",
        "    if needs_download:\n",
        "        download_file(src_url, dst_fn)\n",
        "        if os.path.exists(dst_fn):\n",
        "            print(f'Unzipping {dst_fn} after download...')\n",
        "            try:\n",
        "                with zipfile.ZipFile(dst_fn, 'r') as zip_ref:\n",
        "                    zip_ref.extractall('.')\n",
        "                print('Unzip completed.')\n",
        "            except zipfile.BadZipFile:\n",
        "                print(f'Error: Downloaded {dst_fn} is still not a valid zip file. Please check the source URL or download manually.')\n",
        "            except Exception as e:\n",
        "                print(f'An unexpected error occurred during unzipping after download: {e}')\n",
        "        else:\n",
        "            print(f'Error: Download of {dst_fn} failed. Cannot proceed with unzipping.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t4TyO3Mnetf"
      },
      "source": [
        "Since MATLAB files are still widely-used, Python has excellent routines for loading MATLAB files.  The function below uses the `scipy.io` package to extract the relevant fields from the MATLAB file.  Specifically, the function extracts the training and test data from MATLAB file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "DgrLFShHnetf"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "def load_emnist(file_path='emnist-digits.mat'):\n",
        "    \"\"\"\n",
        "    Loads training and test data with ntr and nts training and test samples\n",
        "    The `file_path` is the location of the `eminst-balanced.mat`.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the MATLAB file\n",
        "    mat = scipy.io.loadmat(file_path)\n",
        "\n",
        "    # Get the training data\n",
        "    Xtr = mat['dataset'][0][0][0][0][0][0][:]\n",
        "    ntr = Xtr.shape[0]\n",
        "    ytr = mat['dataset'][0][0][0][0][0][1][:].reshape(ntr).astype(int)\n",
        "\n",
        "    # Get the test data\n",
        "    Xts = mat['dataset'][0][0][1][0][0][0][:]\n",
        "    nts = Xts.shape[0]\n",
        "    yts = mat['dataset'][0][0][1][0][0][1][:].reshape(nts).astype(int)\n",
        "\n",
        "    print(\"%d training samples, %d test samples loaded\" % (ntr, nts))\n",
        "\n",
        "    return [Xtr, Xts, ytr, yts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjysxlR2netf"
      },
      "source": [
        "Use the function above to get all the digit images from the `emnist-digits.mat` file.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_bB1FCsnetf",
        "outputId": "3eb57718-bc52-4af7-d78a-3f65ab59c4ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240000 training samples, 40000 test samples loaded\n"
          ]
        }
      ],
      "source": [
        "# TODO:  Load the digit data from emnist-digits.mat\n",
        "# Xtr_dig, Xts_dig, ytr_dig, yts_dig = ...\n",
        "Xtr_dig, Xts_dig, ytr_dig, yts_dig = load_emnist(digits_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV9FXlulnetg"
      },
      "source": [
        "Next, use the function above to get all the letter characters from the `emnist-letters.mat` file.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TEIMqK5netg",
        "outputId": "d0d2fd78-1ce8-46bd-96b5-d6721577fed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124800 training samples, 20800 test samples loaded\n"
          ]
        }
      ],
      "source": [
        "# TODO:  Load the digit data from emnist-letters.mat\n",
        "# Xtr_let, Xts_let, ytr_let, yts_let = ...\n",
        "Xtr_let, Xts_let, ytr_let, yts_let = load_emnist(letters_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1pAPkfunetg"
      },
      "source": [
        "We will use the function from the demo to plot the digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "id": "gGqhvmPqnetg"
      },
      "outputs": [],
      "source": [
        "def plt_digit(x,y=None):\n",
        "    nrow = 28\n",
        "    ncol = 28\n",
        "    xsq = x.reshape((nrow,ncol))\n",
        "    plt.imshow(xsq.T,  cmap='Greys_r')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    if y != None:\n",
        "        plt.title('%d' % y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "085EOQUNnetg"
      },
      "source": [
        "Plot 8 random samples from the digit training data.  You can use the `plt_digit` function above with `subplot` to create a nice display.  You may want to size your plot with the `plt.figure(figsize=(10,20))` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "tf6p7WLcnetg",
        "outputId": "12066981-8869-4a59-ff98-c948f59b10e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x2000 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "n_samples = 8\n",
        "fig = plt.figure(figsize=(10, 20))\n",
        "\n",
        "# Get random indices\n",
        "rnd_idx = np.random.choice(Xtr_dig.shape[0], size=n_samples)\n",
        "\n",
        "for i, idx in enumerate(rnd_idx):\n",
        "    plt.subplot(1, n_samples, i + 1)\n",
        "    plt_digit(Xtr_dig[idx], ytr_dig[idx])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KICycOJknetg"
      },
      "source": [
        "Next, plot 8 samples from the letters training data.  You should see that the labels go from 0 to 25 corresponding to `a` to `z`.  Upper and lower case letters belong to the same class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "collapsed": true,
        "id": "IRTWwqBvnetg"
      },
      "outputs": [],
      "source": [
        "# TODO:  Plot 8 random samples from the training data of the letters\n",
        "def plt_letter(x,y=None):\n",
        "  nrow = 28\n",
        "  ncol = 28\n",
        "  xsq = x.reshape((nrow,ncol))\n",
        "  plt.imshow(xsq.T,  cmap='Greys_r')\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  if y != None:\n",
        "        plt.title('%d' % y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 20))\n",
        "n_samples = 8\n",
        "rnd_idx = np.random.choice(Xtr_let.shape[0], size=n_samples)\n",
        "\n",
        "for i, idx in enumerate(rnd_idx):\n",
        "  plt.subplot(1, n_samples, i + 1)\n",
        "  plt_letter(Xtr_let[idx], ytr_let[idx])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "2MH_EP4v2eEP",
        "outputId": "b95bb6e7-9501-4b89-9345-4ca1da155782"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x2000 with 8 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAACWCAYAAAAojlC3AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALupJREFUeJzt3XmUVPWZxvEXBRFoaHYQZAeJgmyyelAEdARRcImAIg4hGiUgnDCTGM2JW9SocTCKE6MyARGIYDAqqLgwooAooKzKJiCyI/tOQGr+mGOd+z6NVV103aququ/nHM+5T9+m+3b96m7WfX9viUgkEjEAAAAAABCKM9K9AQAAAAAAZDNuvAEAAAAACBE33gAAAAAAhIgbbwAAAAAAQsSNNwAAAAAAIeLGGwAAAACAEHHjDQAAAABAiLjxBgAAAAAgRNx4AwAAAAAQIm68AQAAAAAIUc7deA8aNMhKlCjxo/9t3rw53ZuI03Dw4EG7//77rUePHla5cmUrUaKEjRs37pTfe/LkSXvuueesVatWVqZMGatSpYp169bNlixZktqNxmlZsGCBDRs2zJo1a2blypWzunXrWt++fW316tUFvpexznyJ7NsrVqywHj16WF5enlWuXNkGDhxo3333XWo3GKetsGP94osvWpcuXaxGjRpWunRpa9Cggf3sZz+zb775JuXbjNOTyH49ZcoU69ixo1WsWNGqVKliXbp0sbfeeiu1G4zTUtjz9fz58+2Xv/ylXXTRRVaqVCkrUaJEmrYYRZHIfv3ss8/a+eefb6VLl7batWvbyJEj7dChQ6nd4DQome4NSLU77rjDLr/8cve1SCRid955p9WvX99q166dpi1DUezcudMeeughq1u3rrVs2dJmzZr1o987ePBgmzhxot166602bNgwO3TokC1atMh27NiRug3GaXv88cdt7ty5duONN1qLFi1s27Zt9uyzz1qbNm3s008/tebNm0e/l7HOfIXdtzdt2mSXXnqp5efn26OPPmoHDx60J5980pYtW2bz58+3s846K7UbjoQVdqwXLVpkDRo0sN69e1ulSpVs/fr19uKLL9r06dNtyZIlVqtWrdRuOBJW2LEePXq0DR8+3Hr16mWPPfaYHT161MaNG2dXX321TZ061a6//vrUbjgSUtjz9dtvv21jxoyxFi1aWMOGDU/5P9JR/BV2v7777rvtiSeesJ/+9Kc2YsQI++qrr2z06NH25Zdf2rvvvpvajU61CCKzZ8+OmFnkkUceSfem4DQdPXo0snXr1kgkEoksWLAgYmaRsWPHFvi+yZMnR8ws8tprr6V4C5Esc+fOjRw7dsx9bfXq1ZHSpUtHBgwYEP0aY50dCrtvDxkyJFKmTJnIhg0bol97//33I2YWef7551O1uSiCwo71qSxcuDBiZpE//vGPIW4hkqWwY92kSZNIu3btIidPnox+bd++fZG8vLxI7969U7W5OE2FPV9v27Ytcvjw4UgkEokMHTo0wu1JZirMfr1ly5ZIyZIlIwMHDnRfHz16dMTMIm+++WaqNjctcu5R81OZNGmSlShRwm6++eZ0bwpOU+nSpa1mzZpxv2/UqFHWvn17u+666+zkyZM58VhLtrn44osLfHrZpEkTa9asma1YsSL6NcY6OxR23546dapdffXVVrdu3ejXLr/8cjvvvPNsypQpYW4ikqSwY30q9evXNzOzvXv3Jm+DEJrCjvX+/futevXq7tHjChUqWF5enpUpUybMTUQSFPZ8XaNGDcYzCxRmv543b56dOHHC+vfv777+Q37llVdC277iIOdvvI8fP25Tpkyxiy++OHriRnbav3+/zZ8/39q1a2f33nuv5efnW15enjVs2JAL8wwXiURs+/btVrVqVTNjrHPN5s2bbceOHda2bdsC69q3b2+LFi1Kw1YhbLt27bIdO3bYwoUL7Wc/+5mZmXXv3j3NW4Vkuuyyy2zGjBk2evRo++abb2zlypU2dOhQ27dvn40YMSLdm4fToOdr5JZjx46ZmRX4Hy1ly5Y1M7PPP/885duUSjlX463effdd27Vrlw0YMCDdm4KQrV271iKRiL3yyitWsmRJe+KJJyw/P9+efvpp69+/v1WoUMF69OiR7s3EaZg4caJt3rzZHnroITNjrHPN1q1bzczsnHPOKbDunHPOsd27d9uxY8esdOnSqd40hKh27drRi7gqVarYM888Y1dccUWatwrJ9Mwzz9jOnTtt+PDhNnz4cDMzq1q1qs2cOdM6deqU5q3D6dDzNXJL06ZNzcxs7ty51rVr1+jXZ8+ebWaW9ZNc5/yN96RJk6xUqVLWt2/fdG8KQnbw4EEz+/9PST799FPr0KGDmZn17t3bGjRoYA8//DA3Yxnoh09AOnXqZP/+7/9uZox1rjly5IiZ2SlvrM8+++zo93DjnV3eeecdO3r0qK1YscImTJhAOUkWKlu2rDVt2tTOPfdcu/rqq+3AgQP21FNP2fXXX2+zZ8+2xo0bp3sTkYBTna+RW9q0aWMdOnSwxx9/3GrXrm1du3a1FStW2JAhQ6xUqVLR83m2yukb74MHD9obb7xhV155pVWpUiXdm4OQ/fBYS4MGDaI3YmZmeXl5ds0119iECRPsxIkTVrJkTu8WGWXbtm3Wq1cvy8/Pt3/84x925plnmhljnWt+GO8fPv0MOnr0qPseZI8fPi3p2bOn9enTx5o3b255eXk2bNiwNG8ZkuXGG2+0kiVL2rRp06Jf69OnjzVp0sR+97vf2eTJk9O4dUjEj52vkXumTp1q/fr1s8GDB5uZ2ZlnnmkjR460jz76yFatWpXmrQtXTtd4v/7663b48GEeM88RP7SYqVGjRoF11atXt+PHj/OJSQbZt2+f9ezZ0/bu3WszZsxwLYQY69zywyPmPzxyHrR161arXLkyn3ZnuUaNGlnr1q1t4sSJ6d4UJMm6detsxowZ1rt3b/f1ypUrW+fOnW3u3Llp2jIkKtb5Grmndu3aNmfOHFu9erV9/PHHtmnTJnviiSds48aNdt5556V780KV0x/3TJw40fLy8goc1JGdatWqZTVr1jxl/ciWLVvs7LPPtvLly6dhy5Coo0eP2jXXXGOrV6+2Dz74wC644AK3nrHOLbVr17Zq1arZwoULC6ybP3++tWrVKvUbhZQ7cuTIKZ96QGbavn27mZl9//33BdYdP37cTpw4kepNwmmId75G7mrSpIk1adLEzMy++uor27p1qw0aNCi9GxWynP3E+7vvvrMPPvjArrvuuuhMesh+/fr1s40bN9r7778f/drOnTvtjTfesG7dutkZZ+TsLpExvv/+e+vXr5/NmzfPXn311R+dYIexzi033HCDTZ8+3TZu3Bj92syZM2316tV24403pnHLkEwnTpywPXv2FPj6/PnzbdmyZaec2R6ZqXHjxnbGGWfY5MmTLRKJRL++adMmmz17trVu3TqNW4fCKOz5Grnt5MmT9pvf/MbKli1rd955Z7o3J1Q5+4n35MmT7cSJEzxmnkWeffZZ27t3r23ZssXMzKZNm2abNm0yM7O77rrL8vPz7Z577rEpU6bYDTfcYCNHjrT8/Hz761//asePH7dHH300nZuPQvqP//gPe/PNN+2aa66x3bt324QJE9z6W265xcyMsc4ihdm37733Xnv11Veta9euNmLECDt48KD96U9/sgsvvDDaagrFX7yxjkQiVqdOHevXr581a9bMypUrZ8uWLbOxY8dafn6+/f73v0/n5iMB8ca6WrVqNnjwYBszZox1797drr/+ejtw4ID95S9/sSNHjtg999yTzs1HIRT2fL1hwwZ7+eWXzcyiTy49/PDDZmZWr149GzhwYAq3GkVRmPP1iBEj7OjRo9aqVSs7fvy4TZo0yebPn28vvfSS1a1bN52bH75IjurYsWOkevXqkRMnTqR7U5Ak9erVi5jZKf9bv3599PvWrl0bue666yIVKlSIlClTJtKtW7fI/Pnz07fhSEiXLl1+dJz1kMZYZ4fC7tvLly+P/Nu//VukbNmykYoVK0YGDBgQ2bZtW/o2HAmLN9bHjh2LjBgxItKiRYtIhQoVIqVKlYrUq1cv8vOf/9y9F1D8FWa/Pn78eGT06NGRVq1aRfLy8iJ5eXmRrl27Rv73f/83vRuPQins+frDDz/80e/p0qVL+v4AJKww+/XYsWMjLVu2jJQrVy5Svnz5SPfu3XNmny4RiQSe3wEAAAAAAElFkSMAAAAAACHixhsAAAAAgBBx4w0AAAAAQIi48QYAAAAAIETceAMAAAAAECJuvAEAAAAACFHJwnzTyZMnbcuWLVa+fHkrUaJE2NuEIopEInbgwAGrVauWnXFGYv9vhbHOLIx17mCscwvjnTsY69zBWOcOxjp3JDTWhWn2vXHjxh9ths5/xfe/jRs3JtzYnbHOzP8Y69z5j7HOrf8Y79z5j7HOnf8Y69z5j7HOnf8KM9aF+l8w5cuXL8y3oZg5nXFjrDMTY507GOvcwnjnDsY6dzDWuYOxzh2FGbdC3XjzmENmOp1xY6wzE2OdOxjr3MJ45w7GOncw1rmDsc4dhRm3QtV44/Tps/7xnv0/ceJEmJuTda699lqXO3To4PKDDz4YXT569GgqNglAMVKyZHJPcxyjAQDA6WBWcwAAAAAAQsSNNwAAAAAAIeLGGwAAAACAEFHjnWRlypRxuW/fvi63bdvW5QMHDrg8bty46PKaNWvcukgkkoQtzC5XXHGFy0OGDHG5devW0eWrrrrKrTt58mR4G4asFq9uWCfYCM50uX//frcuF2uG9fU766yzXK5du3bMfOWVV0aXK1So4NbpPBq635ctWzahbT18+LDLH330kcsjR450eefOnQn9fADJEW9OHT3O6LGjatWqMX9+cN/esWOHW8f1BJAcic6NFY/um+neV/nEGwAAAACAEHHjDQAAAABAiLjxBgAAAAAgRDlZ4x2sv4xXNx2v1kBrFfv37+/yn/70J5crVqzo8vfff+9yu3btosu33HKLW7d9+/aY25qL9PVUu3btii7rWJ955pkua12u1n/VqlUr5u/6+uuvXaZveHIlUlddv359t6506dIud+zY0eXgXACnou8znVtA3zsq+Pv37t3r1t13330uB+d5yFSlSpVyuVOnTi737NnT5bp167rcuXNnl3VfLFeuXHQ5Xv1XUevDqlSp4vJNN93k8pgxY1z++OOPi/T7ABTO2Wef7XJ+fr7L1apVc1lruBs3buxyy5YtY/6+xYsXR5enT5/u1u3evdvl48ePx/xZ6aLXPUF6PQqEQa/ldD++4YYbXG7atKnLup8rreGeNWuWy3PmzHE51fdWfOINAAAAAECIuPEGAAAAACBE3HgDAAAAABCirKjx1noBrePROp8LLrggurxlyxa3TnvsBmuuzQrWAOnvvuyyy1yuVKnSj2z1/9NayODPr169ultHjbdZnTp1XNYevapXr17R5Q0bNrh1+vpqLWi8GnC1Z88el7X3MDXfntb1aL2dvv46f0Ks/s3xejeXKVMm5rbEU5S64by8PJcfeOABlydMmOByJvb5btKkicvvvfeey9pPN5l0P403j4fS1/vQoUMu63tH37fB+rF09wtNllh1oWbUhma64DWTnhe1Vvmbb76JuT6ZdF+uWbOmyzrfgh73W7Ro4bJeb2nW84AeOw4cOBBd1jrTqVOnuqzXG6mi56bKlSu7PHTo0OiyXr+OHz/e5TVr1iR565At9Jyg5/R69eq5HDyu6H567rnnuqxzwOg1U6Lno4suuijm73v++eejy6m4TucTbwAAAAAAQsSNNwAAAAAAIcqIR8318Z9WrVq5fO2117qsj3s3bNjwR3+ePlaojygk+kiqPhp17Ngxl+fNm+dymzZtXA4+Eqsti/Sxn1x4dFkfWV20aJHL+ghxrJZg+mhyvEfHE6VlBe3bt3c519sM6eNB2o5F91tV1LZQQcke+3gSfdw50+3YscPlKVOmuNylSxeXdT+OJ/iIpD7yGe+11mP+tm3bXJ42bZrL//jHP1zu1q2by2+99ZbL2fJ4efAxXG33pr799luXi/r4sR4reJQ9ufQR42HDhkWXb7/9drdOy+8GDRrk8tKlS10+cuRIkbatRo0a0eVGjRq5dQ899JDL2hZS20bq+0j3Tc379u1zWctM3nzzzeiyHieKSylgvEfNg62agm0ZzQq2RF27dq3LmXxs09dFrwE4xsSm+5KWpOij5XpfFny8+9JLL3Xr9H0Yq4zQrOA5Xt+Xut/qNYI+eh78ff/6179i/uxk4BNvAAAAAABCxI03AAAAAAAh4sYbAAAAAIAQFcsa72CNj5nZgAEDXB45cqTLWmugtQhaDxCsjY5X1xGvlU+8utODBw+6rK2DhgwZ4nLfvn2jy/p3fvLJJy5/+umnMX93NtCarXg13YnU0u7du9dlHWutb9L68ltvvdVlnQ/gjjvucDnXa7y1rZ/W58WrwcoWeswZNWqUy5nYPkzt3LnTZd1XtMY0Hv3+n//859HlZ555Jua/HTt2rMtjxoxxeeHChS7He/0//PDDmOuzRf369aPLWqOvguctM7P169e7rMflePWBOgfArFmzosvazqq41NZmEj22BtuJaTvW8uXLu9y8eXOXtW1WojXeetwP1n927tzZrWvdurXLes6NV7er9epaC6rn6E2bNrn8+uuvR5c3btzo1ul8Pumi46f1tME5j/T6SucVevXVV10+fPhwMjYxJXR+oIsvvjjmeq3ZDx5ncuEYE28urQsvvNDlwYMHu6zzgOj1XnA/1/1U66iLup/OmDHDZZ1zRPeRVF9z8Yk3AAAAAAAh4sYbAAAAAIAQceMNAAAAAECIikWNt/Zwu/fee13WWgL9fq3j0b6sWpMXrBdbsGCBW6e1hP369XP5rrvucllrZLRWYMmSJS5rfdqePXvsx2gdXJ8+fVxOtDYxE2lfSa3LrlixYsx//9prr0WXtQ/6H/7wB5fj9e/TOkXtNXjTTTe5rPVS+t7KxvGKRV8/fe9rvV6iPy9YN6TrYs3zYFawLjHYw9gs8R7wsfpM6jHnv//7v2P+rGyU6Hu/cePGLt99993R5Xj1Yn/+859dXr58eUK/O1cFz201a9Z06/Q113Oy7svB3sFmBee/0PpA7T0cPG9q3an2dk70vaVzwqhs6O+r46V12z/5yU+iy3qe0tdHaz8/++wzl/X6Kx6d0+dXv/pVdFnrSuNd+2mdtc6D88gjj7i8detWl7UfvV4TZMI5W8dWe6GfddZZ0WWtr9fjrJ739LxZnPp669+iNd06D0WzZs1c1vfWnDlzosv//Oc/3bri9HefLj0m6DH4lltucVl7X+u+GXxfmcWex0VrrnUurHfeecdlreF+++23Xd6xY4fLuh/r9ZjWsx84cCC6nIqx5RNvAAAAAABCxI03AAAAAAAh4sYbAAAAAIAQpaXGW2uGtPZCawu09kLrbObNm+ey1ogvXrzY5WAdkNZoa0331Vdf7bLWMWg9gP6uESNGuJxIP0CtWdF6m1ygNUWTJ092WWsF1V/+8pfostb6J9Lz+1S03lxlax/q06Xv/fPOO8/lAQMGuNyyZcuYP2/ZsmUuB48TwZods4J11VoTFKxxNCtY/6/1YokK9pK+77773LpsqCENm74X4s3tgOTSY5mew7Vnq/b71XN8ovWBwflOgv3FT/Vv49Xhav35ueeeG/P74/VrLup5JBV0G3VOi2Bddry/J14NuNL3jtZX6twoLVq0iC7rWOn11qJFi1yeOnWqy+PHj3dZ688zYewSpde0eXl5Lsfqp6y9rfUcrf2Vi1Nfb71e1ppkzTqH0q233upy8Jj27rvvunXaVzoT3ke6L+lx9LnnnnO5U6dOLut+r+8dvY7ROXyCr9mbb77p1n3++ecu6zweeh9Q1LkW9PiXanziDQAAAABAiLjxBgAAAAAgRNx4AwAAAAAQorTUeFetWtXl2267zeV49Xvao+2FF15wWXvCtWnTxuWmTZtGl7XuQ2vR8vPzXdbagKVLl7r81FNPubxq1SqXi1L3mw29A1Pt/fffjy5v2bLFratXr57L8V7f888/32WtTVNTpkxxORN6gKaS7kt/+9vfXNaaLaXjlUgfbx3Ll19+2WXtLavi1XRp/9f/+Z//iS5r71jE99VXX7kcrPnSGkYVrwYVpxY8T2sdtc678sQTT7i8a9culzt27Oiy7ttaM6l1qsHexN27d3frtK90sOe3WcH+tAMHDnS5V69eLuu+PXr0aJe1N3Rw/gjtT1tc6blI58SIReeaqVSpUszv17GsU6eOy7179/7R79frJT1n6Pw+s2fPdlnn8siEWtyi0jkI9Ho4eN7U/VDHSmu8V69e7XJxqvFW+ndrnbDSuQeC877oPBB6jIn3s4sD3e8uv/xyl3XejVKlSsX8eVrTrcfw9957z+XgfZv2Rd+wYUPMn5Vt+y2feAMAAAAAECJuvAEAAAAACBE33gAAAAAAhCgtNd5FVatWLZeffvppl7UeQGv8gvVq8eoYtO/jqFGjXP773//usvYq1jpU7YUXi9aNLFmyJObPzgVaj6e0JiyY9X1z2WWXuaz1YDoXwWuvveZyvLkI/vrXv8ZcD0/fz0V5f59zzjkuaz3+Qw895HLZsmUT+vla37R48WKX77rrLpc/++yzhH4+vO+++87ldevWRZd1P9VjQLt27VzW/u+5eBw9Fa33bNy4cXQ5Xp9trQXVGmL992vXrnV55cqVLuscDMFt0XlXdJ4W/bc6x8u1117rsr5/VP/+/V3WuUGCf4ue/4srvUaKtQ/o+6Jz584u65w7c+fOdVlf/wEDBris/YKD12taMz9p0iSXH3vsMZd37tzpsh6nc8HmzZtd1h7Ud955Z3RZ6/W1zrlly5Yu6/wGen2cTnrM0Xlbdu/e7fKDDz7osva5DtY8a4/vsWPHurxmzZrENjZFgsfpQYMGuXU333yzyzpXg55H9Zih+9a+fftc1mueL7/8MrqsNd36b+P97kzHJ94AAAAAAISIG28AAAAAAELEjTcAAAAAACFKS4231uGMGTPG5WCfbTOzypUru6x1KJrjCfYeXLRokVs3a9Ysl19//XWXtZYz0f59WrsQq1ex9qwM9gs1y43aRK0lrFmzZszv19csWFuor/UHH3xQxK3ztIZIew8jXMHe21rfpX2EE63pVtrHc8SIES5rLRyKRs8ZwWNh+/bt3To9xt52220uT58+3eXiVKeYTjoXSuvWraPLeo7V11jrI/XcpK+x9v3W8+5vf/tbl4M13vq7/vM//9NlrVvVfV3rhrUXsfYy1hplrSFfunRpdFlrP7PxHK2vp77eeo7W+TSC7yuzgvPs7N27N7ocfG3NzJ588kmXt27dGn+Dc8y//vUvl7XmO9izvVy5cm6dXiPFuj4t7vbs2ePy/v37E/r3weOhziuhx4hsoMeqeGOv83Zor/OHH37Y5WB/ea2J//rrr13W88Hy5ctd1vsw7V1f3GvCM3evAgAAAAAgA3DjDQAAAABAiLjxBgAAAAAgRGmp8db+b5MnT3ZZ6ynuvvtul6tVq+ay1qbp8/1a9/uHP/whujx+/Hi3TvvFam/AoqpSpYrLWu+ktXNBudiTskGDBi7H64P+0ksvuRzs1a1zB6h4vQM1aw3RJZdc4nIujleYdHy0L2Ww1lPrMOP9rHh9bf/2t7+5/Ktf/crlQ4cOxfx9KBodjyVLlkSXdex0bBs2bOiynj9ytcZba/j03BTsj62vqWatK9Wa/DvuuMPlmTNnuqzHyljnXf3dderUiflvgzWtZmaPPvqoy9pTtkePHi5rD1+tMW/VqlV0WV/TbKzxjkfn5AnW55uZ5eXluaz777p166LL06ZNc+s2btyYjE3Mavqe0/f/li1bosu6z2vtsr6f9Vq7OCtfvrzLdevWdVnnFoh17Z2pgu+FVatWuXXBvtpmBV8vzfHq/+PN+xGcJ6R58+ZuXZMmTVzWc/YXX3zhss6npMcFvecrbvjEGwAAAACAEHHjDQAAAABAiLjxBgAAAAAgRGmp8Y5XK6C9sbVnbqVKlWL+e6V122+88UZ0OdV9IKtWreqy1jJkY51JUdSuXTvmeq0P+/zzz10O1v3+/ve/d+tuv/12l/W113ryBx54wOWJEye6vH379pjbisRoPdnQoUNd1p6u8er/g/R9E6x7MzMbNWqUy6NHj3ZZewEjXFq3GOyTHq/Gu2LFii7ffPPNLt9zzz1J2MLMo+dNfZ1q1aoVXY43J8LBgwddXrFihcuLFi1yWfuuJrN2VGtaly1b5vI777wT8/v1HN2/f3+X49XBZjt9L2gv6J49e7qscyrocVrr+z/44IPo8ltvveXWFffazeJAj5W7du1yObgvav19sA7XrOAcRO3atXNZ963iNKeB7td6H6Hn8FjXD8Xp70pEcLt1Lq0ZM2a4rHMgXXXVVS5rn+5LL73UZX3vxLqe1mOG1oN36NDB5eB8I2YFa8SnTp3q8osvvuiy3lOmW26dMQAAAAAASDFuvAEAAAAACFFoj5rrowPBx7X0EV99xEGnsVf66PisWbNc1vYg48aNc3nNmjUxf34q8Wi5p4/7aLs3pY+eTZ8+3eVgm6ff/va3bp1mFe/xSiRXrGOGWcFH/RN5tFxpO4q+ffu6rO0reLS8eAk+qqyPAcYrZdJHqnOVPlLduXNnl7UtVJC27NLHGCdMmOCylnQl81h6+PBhlx955BGX9ZFKfQxejyPz5s1zWc8xZ511lsvB91cunM/Lli3rcrdu3Vzu06ePy3pcVzt27HD59ddfjy7rtRwSp/ta8NF+PXbq+zdYbmJWsO1TcW6fp4+ar1271mVtgajv0+DfoqU0WiqTCfRxa/379fXS/bJ69eouawsvbROox9UKFSpEl4Ntfs0KtpDWY4y2ftNHzfX6bMqUKS7zqDkAAAAAADmEG28AAAAAAELEjTcAAAAAACFKWo23TiV/2223uXz//fdHl4PP+psVrC3Q+kqt4Q7WAJmZLV261GWtXdB6tHRKpG2K1pZlYl1Joho0aOByzZo1Y35/sDWcmdm2bduSti3UdIerRo0aLk+bNs3lVq1auZxITbfWfQbbT5mZDRw40OVUtxVE0axbty66rOcLbXmjdYi9e/d2eeTIkS7nSssinUulUaNGLgdrmfVYqDV1ixcvdnn9+vUuh3ks3bdvn8u6r2udsG5LrBrYwghez2gtYjbODaHXetpmSOnrq/WW2rox+F4qbrWZmUjrrhcsWBBd/slPfuLWdenSxeUqVaq43L17d5dfeukll7Vll56HU0nvM7Q+Xedq0PuE4FxSep25adOmZGxiWun7Qsdq5cqVMfMnn3wS8+frfAHBY6Ne23Xs2NHl3/3udy7ruUrnaWnTpo3LF1xwgctar57ua3s+8QYAAAAAIETceAMAAAAAECJuvAEAAAAACFHSarz1mf27777b5WC9hdZc/frXv3ZZa7R27tzpcnGq2Y5Ha7o7dOjgcqzegbNnz3brNm/enOStK35q167tstZnqm+//TbMzUERaI2P1lhNnDjR5YsuuqhIv2/Pnj3R5UsuucStW7VqlcuJ1nGieAmOn84BovVeOjdAtWrVXG7ZsqXLev7JVqVLl3ZZayKDx1495+o5+eOPP3Y5WB9ZGFpvGavXum6Lzvmi9eaJ1pnqXCpa86+vU/BYU7duXbfu66+/djmTrl2SJV6N96JFi1zOhblsUklreT/77LPostZwa62tHiMaNmzo8uWXX+7yjBkzXF69enViG5tE9erVc1mP8/HmYwj2qdZ7Fp1HKhcleiwLvr5Llixx6/bu3etynz59XL7wwgtd1r7fOu9E69atXZ43b57L6Z47gk+8AQAAAAAIETfeAAAAAACEiBtvAAAAAABCdNo13lo3p8/kV61a1eVgr+3hw4e7dcG+gmbZ1ftS6wkHDRrkstZ4B2sXtX45G+tK9H2kfSG1xlvr9Z5++ulwNgxFpj1Cn3vuOZe1FldpjbjWCm7ZssXlxx9/PLq8YsWKmP8W2WPcuHEu33zzzS5rn2E95gwbNszl4LnKLL29aNMpuM9oTd4rr7zisvbvjVf/p3Of6HlSjw3B86LWl7/88ssuJzpeuq06l4rOtXLVVVe5XLly5ehy586d3TqtXdy2bVtC21YcxTsuK62n1Pk2OFan1po1a6LLf//73926vn37utyuXTuXde6F3/zmNy43bdo05vpDhw4ltK2J0OP6tdde6/I111wT8/v37dvncnDuAT3mMEdM0ej7QI8BDzzwgMu33367y/o+1fsovcecNm2ay+vXr3c51XNv8Ik3AAAAAAAh4sYbAAAAAIAQceMNAAAAAECIktbHW2mdTrCOO5trupXWujdu3NhlrZcK1j688847bl029gDV/q3aI1Vfn+XLl7u8Y8eOcDYMCbvxxhtdfv75512O1ZvXLH7toNaRtm3b1uUDBw5El7WGNNW0d6pmJI/2WNV6riFDhsT89127dnW5RYsWLudKX299jwbPy3rO1tck0d7L8Xo779q1y+VatWpFl3W8NReVXo/s37/fZa3vLFeuXHS5UaNGbl358uVdzoYa73j09dH3ysSJE11OtOc7iiY4Pvraz5o1y2Xth6y9r2vUqOHyTTfd5PK6detcnjRpksvBuup4cxjp9YFeW2uP8SuuuMJl7Vmu71Ot4w5eWzLvQLh0Licd60SVLVvWZe1Hn2584g0AAAAAQIi48QYAAAAAIETceAMAAAAAEKLTrvHWeuN3333XZe27lp+fH13W5+2zqcZbaxO0P6nWyKhgPdnWrVuTt2HFlNblaE2c+vzzz12mdja19P1ds2bN6PKvf/1rty7Rmu54tJ7/4Ycfdrk41WHNnz/f5QkTJkSX6QGaXEeOHHF59OjRLuu5SPu3ap2i9vXO1hpvrTeeOXOmy8Ee1OPHj3frNm7c6HKi+54et7XW9KmnnnK5efPm0WWd52P79u0J/e549G/RbdX1wfpEnaOkuNUWpoLW6r799tsuz5s3z2WOh+mj723tp3zw4EGX9fpMj6V5eXku9+vXz+XgPCxmZqtXr44ua4210nlbOnTo4HKrVq1c1mtLnU9I/7YZM2a4vHTp0ugy15mJ0/dGkI5F8P7QrGD/+PPOO8/leNeOhw8fdjnROUjCxifeAAAAAACEiBtvAAAAAABCxI03AAAAAAAhSlofb63P0LqdK6+8Mro8ePBgt+6FF15wWXt6ZpImTZq4/MADD7isNTBa3x7sQbtp06bkblwG0no67amKcGld1ahRo1y+5ZZbosuVKlWK+bOK2puxffv2MXNx8otf/MLl4Os0dOhQty5Y55aptJ4r3lwWetzTOUOK4ttvv3X50KFDLms9mfYQveSSS1zWvy2Z25pOwR66ZmZz5sxx+csvv4wua013smvmtIbyo48+cnnx4sXRZd1u6i9TK149v9ZX6twBa9euTfo24fTovvPqq6+6rL2v+/fv73KbNm1c1mPlRRdd5HKzZs1cDs4HEO+4qtcPZcqUcVnPOXrtoj9fe4rfd999Lgffx5l6jAm+ZtWrV3frijofhb6+ev0XvOcz8/c+lStXdusaNWrkcnBOj8Jsm87z8swzz7is5690n8P5xBsAAAAAgBBx4w0AAAAAQIi48QYAAAAAIESh1XhrHU+wHnPkyJFu3XvvvefyypUrk7VZodOalkGDBrncsWNHl7WecMmSJS4/++yz0WWtW8hG2uc8npdeeimkLYFZwffnk08+6fIvf/lLl4N1PkWt4VbJ/nmppPVPnTp1ii537tzZrcuUGu/ge+O6665z67T2X/u9al2o1mG3bdvW5aL09tU5QlatWuWy9gjV91nZsmVP+3dnEq2z13N4vL66YSpO26I15bHmDMjUWtDg3Cn6N+g5IR6t8dacaM93pI5ec3766acu16tXz+Xzzz/f5bPPPttlPQ/q+mBO9H2hx23NenzTHuILFy50Wd+n2dBfPlgb3aNHD7euadOmLuvcJ/HocUFrxnWulOBYaz2+Zq3f17HVsdH37RdffOEyfbwBAAAAAMgh3HgDAAAAABAibrwBAAAAAAhR0mq8v/vuO5fHjh3rcosWLaLLWtfbq1cvlzds2OByca511pqV+vXru6w1LlrH8tlnn7mc7T0utSZoxowZLmvdiNbdZEo9bKbS1/+mm25yWd/PqZTO2kD93YnWnwdrVD/55JOkbFOqBd8b3bp1c+vq1KkT899qfZ322dT3nb7eidTO6tisW7fOZa0nz+S5BJB82uNVr2V0zoBgL+MPP/zQrdu2bVuSty45dH8KXncEeyubFTzm6/6i++rmzZtd1n0/U+vgc4GO5YIFC1zW61O9Vr/qqqtcDl73mxWcPyM4R1K8c6zeB2gNt87tMW3aNJe1pvuVV15xORtqunVfDZ6X77//frfunHPOcVnrrIsq0bkhgvS6X+fZmDlzpsvffPONy8uXL3e5uM0rwSfeAAAAAACEiBtvAAAAAABCxI03AAAAAAAhSlqNt9ZHTJ8+3eXBgwdHl7WP6j333OPy7t27XR4/fnzM35VKWtMd/LvMCvbK0zqVPXv2uDx//nyXs6HOJEj7nGsNXLy6Eu3fSn1YuPT1XbZsmcvdu3f/0X8bry5Xs9btaH2Svnf27t3r8ltvvRXz5yfTkiVLXG7QoIHL2sNSt2X06NHR5TVr1iR561Iv2Pe3MLS2b9iwYS4H62TNCr7e2k82SN83HTp0cLlnz54ux6s90/oy5LaNGze6rPOSBOtgd+zY4dbpMa640ONT8Fiq1zTNmzd3Wa9p9Lj8wgsvuKzz/3AOzxxaR63XY2+//bbLu3btcrl9+/Yut27d2uUqVapEl7XXcrAHtVnBGm29lta5BN544w2XtR5da8KRXIns53rf89VXX7kcrz5f59IorsfdH/CJNwAAAAAAIeLGGwAAAACAECXtUXOlj1wFHz9q0qSJW6ePaf7iF79wec6cOS6n81FNfexq5MiRLpcvX95lfWzx0UcfdXnKlCkuZ/tjWPEe89THh/T1Rrj0/Td8+HCX33//fZerV68eXdY2NPqo17fffuuyPi6kx4FatWq5/MUXX7isLSTCbBmhr0uirTK0RVEmCv4Nf/7zn906LUFo2bKly1pSoo8cataxTGRs9VHYeO3C9JjzwAMPuJwNY4fTp4+kat6+fXsqNycUwb/hv/7rv9w6PQdv2rTJ5S+//NLlxYsXu5xt5XO5TMdy5cqVLmu710mTJrlcuXJll8uUKfOjP1tLiPSeQq83VC4et/U1DJbJPPjgg25d06ZNXc7Pzw9vw4ReT2mZgJYXa7nPoUOHwtmwFOETbwAAAAAAQsSNNwAAAAAAIeLGGwAAAACAEIVW4621BsF6Tn2+v23bti5rDVXNmjVd/vrrr10Os7ZT6wO1Lc7UqVNd1nZj2n5h4sSJLh85cqSom1isaZ3NY4895vIf//hHl7W+8uDBg6FsFwpnxYoVLuv8DOeee250Wet0tMVDNsn2uRji0brWW2+91WVtF9a3b1+X49Vdp9KECRNc1nk3gGwXPJ599NFHbp3WbGt9pbbuoU1T7orXQjQb5kPIJMF98eWXX3brEp2nJpWyvT6/+L7yAAAAAABkAW68AQAAAAAIETfeAAAAAACEqESkEAXS+/fvT2qPN60tiFdrEK9uJJUS3XZ9eVPZ03Lfvn0FeiPHk+yxVloD36JFC5cXLFjgcpj1+9mkOI41wpGJY12yZGjTiRRZcTq/nEomjjdOD2OdOxjr3MFY547CjDWfeAMAAAAAECJuvAEAAAAACBE33gAAAAAAhCgthXfFvaYulkze9uJAe3zOnz8/TVsCIFWyvS8nAABAPHziDQAAAABAiLjxBgAAAAAgRIW68aalU2Y6nXFjrDMTY507GOvcwnjnDsY6dzDWuYOxzh2FGbdC3XgfOHCgyBuD1DudcWOsMxNjnTsY69zCeOcOxjp3MNa5g7HOHYUZtxKRQtyenzx50rZs2WLly5e3EiVKJGXjEJ5IJGIHDhywWrVq2RlnJFZNwFhnFsY6dzDWuYXxzh2Mde5grHMHY507EhnrQt14AwAAAACA08PkagAAAAAAhIgbbwAAAAAAQsSNNwAAAAAAIeLGGwAAAACAEHHjDQAAAABAiLjxBgAAAAAgRNx4AwAAAAAQov8DrXr8hQV0jmYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1_epE11netg"
      },
      "source": [
        "## Creating a Non-Digit Class\n",
        "\n",
        "SVM classifiers are VERY SLOW to train.  The training is particularly slow when there are a large number of classes, since the one classifier must be trained for each pair of labels.  To make the problem easier, we are going to lump all of the letters in one class and add that class to the digits.  \n",
        "\n",
        "Before we begin, we first need to remove all the letters corresponding to `i/I`, `l/L` and `o/O`.  The reason is that these letters would get confused with the digits `0` and `1`.  Create arrays `Xtr_let_rem` and `ytr_let_rem` from the data `Xtr_let` and `ytr_let`, where the samples `i` with `ytr_let[i] == 9, 12` or `15` are removed.   Create `Xts_let_rem` and `yts_let_rem` similarly.\n",
        "\n",
        "If you are clever, you can do this without a for-loop via python broadcasting and `np.all(..., axis=1)` command.  But, you will receive full marks if you use a `for-loop`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "collapsed": true,
        "id": "h-1vo9Xjnetg"
      },
      "outputs": [],
      "source": [
        "remove_list = np.array([9,12,15])\n",
        "\n",
        "# Create a boolean mask where True means the label is NOT in remove_list\n",
        "mask_tr = ~np.isin(ytr_let, remove_list)\n",
        "mask_ts = ~np.isin(yts_let, remove_list)\n",
        "\n",
        "# Apply the masks to filter the data\n",
        "Xtr_let_rem, ytr_let_rem = Xtr_let[mask_tr], ytr_let[mask_tr]\n",
        "Xts_let_rem, yts_let_rem = Xts_let[mask_ts], yts_let[mask_ts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ4AA9jdnetg"
      },
      "source": [
        "Since training and testing an SVM is VERY SLOW, we will use only a small subset of the training and test data.  Of course, you will not get great results with this small dataset.  But, we can at least illustrate the basic concepts.  \n",
        "\n",
        "Create arrays `Xtr1_dig` and `ytr1_dig` by selecting 5000 random training digit samples from `Xtr_dig` and `ytr_dig`.  Create arrays `Xtr1_let` and `ytr1_let` by selecting 1000 random training letter samples from `Xtr_let_rem` and `ytr_let_rem`.  Similarly, create test arrays `Xts1_dig,Xts1_let,yts1_dig,yts1_let` with 5000 digits and 1000 letters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": true,
        "id": "meFYXH5dnetg"
      },
      "outputs": [],
      "source": [
        "# Number of training and test digits and letters\n",
        "ntr_dig = 5000\n",
        "ntr_let = 1000\n",
        "nts_dig = 5000\n",
        "nts_let = 1000\n",
        "\n",
        "# Create sub-sampled training and test data\n",
        "# Digits training data\n",
        "rnd_idx_tr_dig = np.random.choice(Xtr_dig.shape[0], size=ntr_dig, replace=False)\n",
        "Xtr1_dig, ytr1_dig = Xtr_dig[rnd_idx_tr_dig], ytr_dig[rnd_idx_tr_dig]\n",
        "\n",
        "# Digits test data\n",
        "rnd_idx_ts_dig = np.random.choice(Xts_dig.shape[0], size=nts_dig, replace=False)\n",
        "Xts1_dig, yts1_dig = Xts_dig[rnd_idx_ts_dig], yts_dig[rnd_idx_ts_dig]\n",
        "\n",
        "# Letters training data\n",
        "rnd_idx_tr_let = np.random.choice(Xtr_let_rem.shape[0], size=ntr_let, replace=False)\n",
        "Xtr1_let, ytr1_let = Xtr_let_rem[rnd_idx_tr_let], ytr_let_rem[rnd_idx_tr_let]\n",
        "\n",
        "# Letters test data\n",
        "rnd_idx_ts_let = np.random.choice(Xts_let_rem.shape[0], size=nts_let, replace=False)\n",
        "Xts1_let, yts1_let = Xts_let_rem[rnd_idx_ts_let], yts_let_rem[rnd_idx_ts_let]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw1F23pinetg"
      },
      "source": [
        "Next, we create data by combining the digit and letter arrays.\n",
        "* Create an array `Xtr` by stacking `Xtr1_dig`, `Xtr1_let`.  This should result in 6000 total samples.\n",
        "* Create a new label vector `ytr` where `ytr[i] = ytr1_dig[i]` for any digit sample and `ytr[i]=10` for any letter sample.  Thus, all the letters are lumped into a single class with label 11.\n",
        "\n",
        "Create test arrays `Xts` and `yts` similarly.\n",
        "\n",
        "You may wish to use the `np.hstack` and `np.vstack` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "id": "q_zJXCasnetg"
      },
      "outputs": [],
      "source": [
        "# Create combined letter and digit training and test data\n",
        "Xtr = np.vstack((Xtr1_dig, Xtr1_let))\n",
        "# Create ytr: digits keep their labels, letters become class 10\n",
        "ytr = np.hstack((ytr1_dig, 10 * np.ones(ntr_let, dtype=int)))\n",
        "\n",
        "Xts = np.vstack((Xts1_dig, Xts1_let))\n",
        "# Create yts: digits keep their labels, letters become class 10\n",
        "yts = np.hstack((yts1_dig, 10 * np.ones(nts_let, dtype=int)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP3lQ0Vrneth"
      },
      "source": [
        "The training data above takes values from 0 to 255.  Rescale the data from -1 to 1.  This will get slightly better performance on the SVM.  Save the scaled data into arrays `Xtr1` and `Xts1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "collapsed": true,
        "id": "1heYokmIneth"
      },
      "outputs": [],
      "source": [
        "# TODO:  Rescale the data from -1 to 1\n",
        "# Xtr1 = ...\n",
        "Xtr1 = preprocessing.scale(Xtr)\n",
        "# Xts1 = ...\n",
        "Xts1 = preprocessing.scale(Xts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6FDxwfVneth"
      },
      "source": [
        "## Run the SVM classifier\n",
        "\n",
        "First create the SVM classifer. Use an `rbf` classifier with `C=2.8` and `gamma=.0073`. We will look at how to select these parameters laters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": true,
        "id": "4R9ZFFGuneth"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# TODO:  Create a classifier: a support vector classifier\n",
        "# svc = ...\n",
        "svc = svm.SVC(kernel='rbf', C=2.8, gamma=.0073)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxeIFdXZneth"
      },
      "source": [
        "Fit the classifier using the scaled training data.  SVMs are insanely slow to train.  But, in this lab, we have kept the training size very small. So, the fitting should take about a minute or two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "yLYL4h29neth",
        "outputId": "6e6cc970-dc91-4c38-ec86-d800a9e242ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.8, gamma=0.0073)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=2.8, gamma=0.0073)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=2.8, gamma=0.0073)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# TODO:  Fit the classifier on the training data.\n",
        "# This will take about a minute or two\n",
        "svc.fit(Xtr1, ytr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p3b7bJbneth"
      },
      "source": [
        "Measure the accuracy on the test data.  This too will take another huge amount of time.  Print the accuracy.  If you did everything right, you should get an accuracy of around 89%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH36JsOMneth",
        "outputId": "5c57668f-e38c-4c8e-9870-a91a7362eedb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:  0.2606666666666667\n"
          ]
        }
      ],
      "source": [
        "# TODO:  Measure error on the test data\n",
        "error = 1 - svc.score(Xts1, yts)\n",
        "print(\"Error: \", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijL7s70Cneth"
      },
      "source": [
        "The error rate is quite a bit higher than what we got in the digits only case.  Actually, had we done a classifier using all 36 labels instead of collapsing the letters to a single class, the SVM classifier would have done much better.  The reason is that the \"letters\" class is now extremely complex.  \n",
        "\n",
        "Print a confusion matrix.  You should see that the error rate on the \"letters\" class is much higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmd86tiAneth",
        "outputId": "d1081bba-45f9-4a0d-926b-22220a775cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[401   0   0   0   0   0   0   0   0   0 101]\n",
            " [  0 479   0   0   0   0   0   1   0   0  17]\n",
            " [  0   0 249   0   0   0   0   1   3   0 253]\n",
            " [  1   0   1 376   0   2   0   2   1   1 139]\n",
            " [  0   0   0   0 299   0   0   1   0   2 210]\n",
            " [  0   0   0   2   0 290   0   0   3   0 212]\n",
            " [  0   0   0   0   0   2 372   0   0   0 117]\n",
            " [  0   1   1   0   0   0   0 356   0   5 135]\n",
            " [  0   2   1   1   0   0   0   1 298   1 161]\n",
            " [  0   0   0   0   4   0   0   4   0 370 121]\n",
            " [  7   2   3   1   7  12   7   1   6   8 946]]\n"
          ]
        }
      ],
      "source": [
        "# TODO:  Print a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = svc.predict(Xts1)\n",
        "cm = confusion_matrix(yts, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pcaMJsAneth"
      },
      "source": [
        "Print:\n",
        "* What fraction of digits are mislabeled as letters?  \n",
        "* What fraction of letters are mislabeled as digits?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "id": "MaT6IgYineth"
      },
      "outputs": [],
      "source": [
        "# TODO:  Print above two error rates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfeueaKXneth"
      },
      "source": [
        "## Selecting gamma and C via Cross-Validation (Using For-Loops)\n",
        "\n",
        "In the above example, and in the demo, we used a given `gamma` and `C` value.  The selection of the parameters depend on the problem and decent performance of the SVM requires that you select these parameters carefully.  The best way to select the parameters is via cross validation.  Specifically, generally, one tries different values of `gamma` and `C` and selects the pair of values the lowest test error rate.\n",
        "\n",
        "In the code below, we will try to use 3 values for `C` and `gamma` as specified in the arrays `C_test` and `gam_test`.  For each `C` and `gamma` in these arrays, fit a model on the training data and measure the accuracy on the test data.  Then, print the `C` and `gamma` that result in the best accuracy.   \n",
        "\n",
        "Normally, you would try a large number of values for each of the parameters, but an SVM is very slow to train -- even with this small data set.  So, we will just do 3 values of each.  Even then, this could take 30 minutes or so to complete.\n",
        "\n",
        "In this lab, you may do the parameter search over `C` and `gamma` in one of two ways:\n",
        "* This section:  Use for loops and manually search over the parameters.  This is more direct and you will see and control exactly what is happening.\n",
        "* Next section:  Use the `GridSearchCV` method in the `sklearn` package.  This takes a little reading, but once you learn this method, you can more easily use this for complex parameter searches.\n",
        "\n",
        "**You only need to submit the solutions to one of the two sections.**  Pick whichever one you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8uc1AUineth",
        "outputId": "eb8e8cdd-4986-4f9e-b2e7-d79382b75c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.16666667 0.16666667 0.16666667]\n",
            " [0.16666667 0.16666667 0.16666667]\n",
            " [0.16666667 0.16666667 0.16666667]]\n"
          ]
        }
      ],
      "source": [
        "C_test = [0.1,1,10]\n",
        "gam_test = [0.001,0.01,0.1]\n",
        "\n",
        "nC = len(C_test)\n",
        "ngam = len(gam_test)\n",
        "acc = np.zeros((nC,ngam))\n",
        "\n",
        "# TODO:  Measure and print the accuracy for each C and gamma value.  Store the results in acc\n",
        "\n",
        "for i, C in enumerate(C_test):\n",
        "    for j, gamma in enumerate(gam_test):\n",
        "        svc = svm.SVC(kernel='rbf', C=C, gamma=gamma)\n",
        "        svc.fit(Xtr1, ytr)\n",
        "        acc[i, j] = svc.score(Xts, yts)\n",
        "\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "id": "12NMz_Szneth"
      },
      "outputs": [],
      "source": [
        "# TODO:  Print the accuracy matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYd-59GBneth",
        "outputId": "6cf77129-bb29-4b4e-f74a-c5d243396da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Accuracy: 0.1667\n",
            "Best C: 0.1\n",
            "Best gamma: 0.001\n"
          ]
        }
      ],
      "source": [
        "# TODO:  Print the maximum accuracy and the corresponding best C and gamma\n",
        "max_acc = np.max(acc)\n",
        "max_i, max_j = np.where(acc == max_acc)\n",
        "best_C = C_test[max_i[0]]\n",
        "best_gamma = gam_test[max_j[0]]\n",
        "print(f\"Maximum Accuracy: {max_acc:.4f}\")\n",
        "print(f\"Best C: {best_C}\")\n",
        "print(f\"Best gamma: {best_gamma}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "edfg8JVxnets"
      },
      "source": [
        "## Using `GridSearchCV` (Optional Section)\n",
        "\n",
        "\n",
        "In the previous section, you would have likely used `for-loops` to search over the different `C` and `gamma` values.  Since this type of parameter search is so commonly used, `sklearn` has an excellent method `GridSearchCV` that can perform all the operations for you.  In this lab, `GridSearchCV` is not that useful.  But, once you get to more complex parameter searches, the `GridSearchCV` method can save you writing a lot of code.  Importantly, `GridSearchCV` supports parallelization so that fits with different parameters can be fit at the same time.  In this optional section, we will show how to use this method.  \n",
        "\n",
        "**You do not have to do this section, if you did the previous section**.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXNO8il1nets"
      },
      "source": [
        "The `GridSearchCV` method does the train-test split in addition to the parameter search.  In this case, you have already a fixed train-test split.  So, you first need to combine the train and test data back into a single dataset.\n",
        "\n",
        "Create arrays `X` and `y` from `Xtr1`, `Xts1`, `ytr` and `yts`.  Use `np.vstack` and `np.hstack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "collapsed": true,
        "id": "MqIkDE1Rnets"
      },
      "outputs": [],
      "source": [
        "# TODO:  Create combined trained and test data X and y.\n",
        "# X = ...\n",
        "# y = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKailfvUnets"
      },
      "source": [
        "Normally, `GridSearchCV` will do $K$-fold validation and automatically split the data into training and test in each fold.  But, in this case, we want it to perform only one fold with a specific train-test split.  To do this, we need to do the following:\n",
        "* Create a vector `test_fold` where `test_fold[i] = -1` for the samples `i` in the training data (this indicates that they should not be used as test data in any fold) and `test_fold[i] = 0` for the samples `i` in the test data (this indicates that they should be as test data in fold 0).\n",
        "* Call the method  `ps = sklearn.model_selection.PredefinedSplit(test_fold)` to create a predefined test split object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "id": "3e7GhIYWnets"
      },
      "outputs": [],
      "source": [
        "# TODO:  Create a pre-defined test split object\n",
        "# import sklearn.model_selection\n",
        "# test_fold = ...\n",
        "# ps = sklearn.model_selection.PredefinedSplit(test_fold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C769VSpMnets"
      },
      "source": [
        "Next, read about the `GridSearchCV` method to set up a classifier that includes searching over the parameter grid.  \n",
        "* For the `param_grid` parameter, you will want to create a dictionary to search over `C` and `gamma`.  You will also need to select the `kernel` parameter.\n",
        "* Set `cv = ps` to use the fixed train-test split.\n",
        "* Set `verbose=10` to monitor the progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "id": "vqOAt-sanets"
      },
      "outputs": [],
      "source": [
        "# TODO:  Create a GridSearchCV classifier\n",
        "# clf = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMtUrk-3nets"
      },
      "source": [
        "Fit the classifier using the `fit` method.  The fit method will now search over all the parameters. This will take about 30 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "collapsed": true,
        "id": "DE_7Sjgenets"
      },
      "outputs": [],
      "source": [
        "# TODO: Fit the classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Qtr1Prnets"
      },
      "source": [
        "Print the `best_score_` and `best_params_` attributes of the classifier to find the best score and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "collapsed": true,
        "id": "63ZmXmVLnett"
      },
      "outputs": [],
      "source": [
        "# TODO:  Print the best parameter and score of the classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM5c_fsBnett"
      },
      "source": [
        "Finally, you can print the test and train score from the `cv_results_['mean_test_score']` and `cv_results_['mean_train_score']`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "id": "cb7CJzw5nett"
      },
      "outputs": [],
      "source": [
        "# TODO:  Print the mean test score for each parameter value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "id": "nL4FV-Ifnett"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}